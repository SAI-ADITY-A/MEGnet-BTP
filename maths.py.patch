# Patch generated by Pyment v0.3.3

--- a/maths.py
+++ b/maths.py
@@ -23,10 +23,9 @@


 class GaussianExpansion(nn.Module):
-    r"""Gaussian Radial Expansion.
+    """r"""Gaussian Radial Expansion.
     The bond distance is expanded to a vector of shape [m],
     where m is the number of Gaussian basis centers.
-    """

     def __init__(
         self,
@@ -60,14 +59,9 @@
     def forward(self, bond_dists):
         """Expand distances.

-        Parameters
-        ----------
-        bond_dists :
-            Bond (edge) distances between two atoms (nodes)
-
-        Returns:
-        -------
-        A vector of expanded distance with shape [num_centers]
+        :param bond_dists:
+
+
         """
         diff = bond_dists[:, None] - self.centers[None, :]
         return torch.exp(-self.width * (diff**2))
@@ -82,10 +76,12 @@
     `[z_{j-1,n}, z_{j-1, n+1}]`. On the other hand we know precisely the
     roots for j0, i.e., sinc(x).

-    Args:
-        max_l: max order of spherical bessel function
-        max_n: max number of roots
+    :param max_l: max order of spherical bessel function
+    :param max_n: max number of roots
     Returns: root matrix of size [max_l, max_n]
+    :param max_l: int:
+    :param max_n: int:
+
     """
     temp_zeros = np.arange(1, max_l + max_n + 1) * pi  # j0
     roots = [temp_zeros[:max_n]]
@@ -125,8 +121,9 @@
         """Spherical basis functions based on Rayleigh formula. This function
         generates
         symbolic formula.
-
+
         Returns: list of symbolic functions
+

         """
         x = sympy.symbols("x")
@@ -135,6 +132,7 @@

     @lru_cache(maxsize=128)
     def _calculate_smooth_symbolic_funcs(self) -> list:
+        """ """
         return _get_lambda_func(max_n=self.max_n, cutoff=self.cutoff)

     def __call__(self, r):
@@ -150,10 +148,20 @@
         return self._call_sbf(r)

     def _call_smooth_sbf(self, r):
+        """
+
+        :param r:
+
+        """
         results = [i(r) for i in self.funcs]
         return torch.t(torch.stack(results))

     def _call_sbf(self, r):
+        """
+
+        :param r:
+
+        """
         roots = SPHERICAL_BESSEL_ROOTS[: self.max_l, : self.max_n]

         results = []
@@ -172,11 +180,13 @@
         """Spherical Bessel function of order 0, ensuring the function value
         vanishes at cutoff.

-        Args:
-            r: torch.tensor pytorch tensors
-            cutoff: float, the cutoff radius
-            max_n: int max number of basis
+        :param r: torch.tensor pytorch tensors
+        :param cutoff: float, the cutoff radius
+        :param max_n: int max number of basis
         Returns: basis function expansion using first spherical Bessel function
+        :param cutoff: float:  (Default value = 5.0)
+        :param max_n: int:  (Default value = 3)
+
         """
         n = (torch.arange(1, max_n + 1)).type(dtype=torch.float32)[None, :]
         r = r[:, None]
@@ -184,22 +194,23 @@


 def _y00(theta, phi):
-    r"""Spherical Harmonics with `l=m=0`.
-
+    """r"""Spherical Harmonics with `l=m=0`.
+
     ..math::
         Y_0^0 = \frac{1}{2} \sqrt{\frac{1}{\pi}}

-    Args:
-        theta: torch.tensor, the azimuthal angle
-        phi: torch.tensor, the polar angle
-
+    :param theta: torch.tensor, the azimuthal angle
+    :param phi: torch.tensor, the polar angle
     Returns: `Y_0^0` results
-
-    """
     return 0.5 * torch.ones_like(theta) * sqrt(1.0 / pi)


 def _conjugate(x):
+    """
+
+    :param x:
+
+    """
     return torch.conj(x)


@@ -245,6 +256,13 @@


 def _block_repeat(array, block_size, repeats):
+    """
+
+    :param array:
+    :param block_size:
+    :param repeats:
+
+    """
     col_index = torch.arange(array.size()[1])
     indices = []
     start = 0
@@ -258,23 +276,24 @@

 def combine_sbf_shf(sbf, shf, max_n: int, max_l: int, use_phi: bool):
     """Combine the spherical Bessel function and the spherical Harmonics function.
-
+
     For the spherical Bessel function, the column is ordered by
         [n=[0, ..., max_n-1], n=[0, ..., max_n-1], ...], max_l blocks,
-
+
     For the spherical Harmonics function, the column is ordered by
         [m=[0], m=[-1, 0, 1], m=[-2, -1, 0, 1, 2], ...] max_l blocks, and each
         block has 2*l + 1
         if use_phi is False, then the columns become
         [m=[0], m=[0], ...] max_l columns

-    Args:
-        sbf: torch.tensor spherical bessel function results
-        shf: torch.tensor spherical harmonics function results
-        max_n: int, max number of n
-        max_l: int, max number of l
-        use_phi: whether to use phi
-    Returns:
+    :param sbf: torch.tensor spherical bessel function results
+    :param shf: torch.tensor spherical harmonics function results
+    :param max_n: int, max number of n
+    :param max_l: int, max number of l
+    :param max_n: int:
+    :param max_l: int:
+    :param use_phi: bool:
+
     """
     if sbf.size()[0] == 0:
         return sbf
@@ -297,6 +316,11 @@


 def _sinc(x):
+    """
+
+    :param x:
+
+    """
     return torch.sin(x) / x


@@ -305,16 +329,16 @@
     and second derivative at the cutoff
     equals to zero. The function was derived from the order 0 spherical Bessel
     function, and was expanded by the different zero roots.
-
+
     Ref:
         https://arxiv.org/pdf/1907.02374.pdf

-    Args:
-        r: torch.tensor distance tensor
-        cutoff: float, cutoff radius
-        max_n: int, max number of basis, expanded by the zero roots
-
+    :param r: torch.tensor distance tensor
+    :param cutoff: float, cutoff radius
+    :param max_n: int, max number of basis, expanded by the zero roots
     Returns: expanded spherical harmonics with derivatives smooth at boundary
+    :param cutoff: float:  (Default value = 5.0)
+    :param max_n: int:  (Default value = 10)

     """
     n = torch.arange(max_n).type(dtype=torch.float32)[None, :]
@@ -343,6 +367,12 @@

 @lru_cache(maxsize=128)
 def _get_lambda_func(max_n, cutoff: float = 5.0):
+    """
+
+    :param max_n:
+    :param cutoff: float:  (Default value = 5.0)
+
+    """
     r = sympy.symbols("r")
     d0 = 1.0
     en = []
@@ -379,13 +409,10 @@
     """Get segment indices from number array. For example if
     ns = [2, 3], then the function will return [0, 0, 1, 1, 1].

-    Args:
-        ns: torch.tensor, the number of atoms/bonds array
-
-    Returns:
-        object:
-
-    Returns: segment indices tensor
+    :param ns: torch.tensor, the number of atoms/bonds array
+    :returns: Returns: segment indices tensor
+    :rtype: object
+
     """
     a = torch.arange(ns.size(dim=0))
     return a.repeat_interleave(ns, dim=0)
@@ -394,10 +421,9 @@
 def get_range_indices_from_n(ns):
     """Give ns = [2, 3], return [0, 1, 0, 1, 2].

-    Args:
-        ns: torch.tensor, the number of atoms/bonds array
-
+    :param ns: torch.tensor, the number of atoms/bonds array
     Returns: range indices
+
     """
     max_n = torch.max(ns)
     n = ns.size(dim=0)
@@ -414,11 +440,11 @@
 def repeat_with_n(ns, n):
     """Repeat the first dimension according to n array.

-    Args:
-        ns (torch.tensor): tensor
-        n (torch.tensor): a list of replications
-
+    :param ns: tensor
+    :type ns: torch.tensor
+    :param n: a list of replications
     Returns: repeated tensor
+    :type n: torch.tensor

     """
     return torch.repeat_interleave(ns, n, dim=0)
@@ -428,11 +454,10 @@
     """Broadcast state attributes of shape [Ns, Nstate] to
     bond attributes shape [Nb, Nstate].

-    Args:
-        g: DGL graph
-        state_feat: state_feature
-
+    :param g: DGL graph
+    :param state_feat: state_feature
     Returns: broadcasted state attributes
+
     """
     return state_feat.repeat((g.num_edges(), 1))

@@ -441,10 +466,8 @@
     """Broadcast state attributes of shape [Ns, Nstate] to
     bond attributes shape [Nb, Nstate].

-    Args:
-        g: DGL graph
-        state_feat: state_feature
-
+    :param g: DGL graph
+    :param state_feat: state_feature
     Returns: broadcasted state attributes

     """
@@ -455,14 +478,20 @@
     """Scatter sum operation along the specified dimension. Modified from the
     torch_scatter library (https://github.com/rusty1s/pytorch_scatter).

-    Args:
-        input_tensor (torch.Tensor): The input tensor to be scattered.
-        segment_ids (torch.Tensor): Segment ID for each element in the input tensor.
-        num_segments (int): The number of segments.
-        dim (int): The dimension along which the scatter sum operation is performed (default: -1).
-
-    Returns:
-        resulting tensor
+    :param input_tensor: The input tensor to be scattered.
+    :type input_tensor: torch.Tensor
+    :param segment_ids: Segment ID for each element in the input tensor.
+    :type segment_ids: torch.Tensor
+    :param num_segments: The number of segments.
+    :type num_segments: int
+    :param dim: The dimension along which the scatter sum operation is performed (default: -1).
+    :type dim: int
+    :param input_tensor: torch.tensor:
+    :param segment_ids: torch.tensor:
+    :param num_segments: int:
+    :param dim: int:
+    :returns: resulting tensor
+
     """
     segment_ids = broadcast(segment_ids, input_tensor, dim)
     size = list(input_tensor.size())
@@ -476,12 +505,17 @@

 def unsorted_segment_fraction(data: torch.tensor, segment_ids: torch.tensor, num_segments: torch.tensor):
     """Segment fraction
-    Args:
-        data (torch.tensor): original data
-        segment_ids (torch.tensor): segment ids
-        num_segments (torch.tensor): number of segments
-    Returns:
-        data (torch.tensor): data after fraction.
+
+    :param data: original data
+    :type data: torch.tensor
+    :param segment_ids: segment ids
+    :type segment_ids: torch.tensor
+    :param data: torch.tensor:
+    :param segment_ids: torch.tensor:
+    :param num_segments: torch.tensor:
+    :returns: data-> data after fraction.
+    :rtype: torch.tensor
+
     """
     segment_sum = scatter_sum(input_tensor=data, segment_ids=segment_ids, dim=0, num_segments=num_segments)
     sums = torch.gather(segment_sum, 0, segment_ids)
@@ -492,13 +526,14 @@
     """Broadcast input tensor along a given dimension to match the shape of the target tensor.
     Modified from torch_scatter library (https://github.com/rusty1s/pytorch_scatter).

-    Args:
-        input_tensor: The tensor to broadcast.
-        target_tensor: The tensor whose shape to match.
-        dim: The dimension along which to broadcast.
-
-    Returns:
-        resulting input tensor after broadcasting
+    :param input_tensor: The tensor to broadcast.
+    :param target_tensor: The tensor whose shape to match.
+    :param dim: The dimension along which to broadcast.
+    :param input_tensor: torch.tensor:
+    :param target_tensor: torch.tensor:
+    :param dim: int:
+    :returns: resulting input tensor after broadcasting
+
     """
     if input_tensor.dim() == 1:
         for _ in range(0, dim):
